{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0dce16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T12:41:53.679935Z",
     "iopub.status.busy": "2025-03-11T12:41:53.679682Z",
     "iopub.status.idle": "2025-03-11T12:41:59.610889Z",
     "shell.execute_reply": "2025-03-11T12:41:59.610073Z"
    },
    "papermill": {
     "duration": 5.936538,
     "end_time": "2025-03-11T12:41:59.612549",
     "exception": false,
     "start_time": "2025-03-11T12:41:53.676011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/ultralytics-package/ultralytics_package\r\n",
      "Processing /kaggle/input/ultralytics-package/ultralytics_package/ultralytics-8.3.75-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\r\n",
      "Processing /kaggle/input/ultralytics-package/ultralytics_package/ultralytics_thop-2.0.14-py3-none-any.whl (from ultralytics)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Installing collected packages: ultralytics-thop, ultralytics\r\n",
      "Successfully installed ultralytics-8.3.75 ultralytics-thop-2.0.14\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --find-links=/kaggle/input/ultralytics-package/ultralytics_package ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9360bb2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-11T12:41:59.620475Z",
     "iopub.status.busy": "2025-03-11T12:41:59.620195Z",
     "iopub.status.idle": "2025-03-11T12:43:29.713779Z",
     "shell.execute_reply": "2025-03-11T12:43:29.712803Z"
    },
    "papermill": {
     "duration": 90.099705,
     "end_time": "2025-03-11T12:43:29.715724",
     "exception": false,
     "start_time": "2025-03-11T12:41:59.616019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import logging\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from transformers import Pix2StructForConditionalGeneration, Pix2StructProcessor\n",
    "\n",
    "\n",
    "\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "chart_types = {\n",
    "    0: \"horizontal_bar\",\n",
    "    1: \"vertical_bar\",\n",
    "    2: \"dot\",\n",
    "    3: \"line\",\n",
    "    4: \"scatter\"\n",
    "}\n",
    "\n",
    "# Models\n",
    "model_charttype_path = \"/kaggle/input/chart-type-classification/pytorch/default/1/fine_tuned_chart_classification_model_mid_v3_5.h5\"\n",
    "model_Charttype = load_model(model_charttype_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_Deplot = Pix2StructForConditionalGeneration.from_pretrained('/kaggle/input/deplot/pytorch/deplot/1').to(device)\n",
    "processor_Deplot = Pix2StructProcessor.from_pretrained('/kaggle/input/deplot/pytorch/deplot/1')\n",
    "\n",
    "model_Deplot_horizontal = Pix2StructForConditionalGeneration.from_pretrained('/kaggle/input/deplot-finetuned-horizontal/deplot_finetuned_v2').to(device)\n",
    "processor_horizontal = Pix2StructProcessor.from_pretrained('/kaggle/input/deplot-finetuned-horizontal/deplot_finetuned_v2')\n",
    "\n",
    "model_Deplot_line = Pix2StructForConditionalGeneration.from_pretrained('/kaggle/input/deplot-finetuned-line-version-2/deplot_finetuned').to(device)\n",
    "processor_line = Pix2StructProcessor.from_pretrained('/kaggle/input/deplot-finetuned-line-version-2/deplot_finetuned')\n",
    "\n",
    "model_Deplot_dot = Pix2StructForConditionalGeneration.from_pretrained('/kaggle/input/deplot-finetuned-dot/deplot_finetuned').to(device)\n",
    "processor_dot = Pix2StructProcessor.from_pretrained('/kaggle/input/deplot-finetuned-dot/deplot_finetuned')\n",
    "\n",
    "\n",
    "# Load YOLO models\n",
    "tick_model = YOLO(\"/kaggle/input/tick-model-yolo/other/default/2/tick_best.pt\")  # Detects ticks & text boxes\n",
    "scatter_model = YOLO(\"/kaggle/input/scatter-dot-yolo-03/other/default/8/best_scatter_29_date_10_03_2025.pt\")  # Detects scatter points\n",
    "plot_model = YOLO(\"/kaggle/input/plot-model-yolo/other/default/1/plot_best.pt\")  # Detects plot area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b806b953",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T12:43:29.724879Z",
     "iopub.status.busy": "2025-03-11T12:43:29.724396Z",
     "iopub.status.idle": "2025-03-11T12:43:29.733641Z",
     "shell.execute_reply": "2025-03-11T12:43:29.732831Z"
    },
    "papermill": {
     "duration": 0.014932,
     "end_time": "2025-03-11T12:43:29.734952",
     "exception": false,
     "start_time": "2025-03-11T12:43:29.720020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display function for deplot output\n",
    "def display_deplot_output(deplot_output):\n",
    "    deplot_output = deplot_output.replace(\"<0x0A>\", \"\\n\").replace(\" | \", \"\\t\")\n",
    "    second_a_index = [m.start() for m in re.finditer('\\t', deplot_output)][1]\n",
    "    last_newline_index = deplot_output.rfind('\\n', 0, second_a_index)\n",
    "    title = deplot_output[:last_newline_index]\n",
    "    table = deplot_output[last_newline_index + 1:]\n",
    "    data = io.StringIO(table)\n",
    "    df = pd.read_csv(data, sep='\\t')\n",
    "    return df\n",
    "\n",
    "# Function to handle deplot with model and processor\n",
    "def deplot_with_model(path, model, processor, device, font_path, chart_type):\n",
    "    try:\n",
    "        image = Image.open(path)\n",
    "        #display(image)\n",
    "        if chart_type in [\"dot\", \"horizontal_bar\", \"line\"]:\n",
    "            inputs = processor(\n",
    "                images=image,\n",
    "                text=\"Generate data series:\",\n",
    "                return_tensors=\"pt\",\n",
    "                font_path=font_path\n",
    "            )   \n",
    "        else:\n",
    "            inputs = processor(\n",
    "                images=image,\n",
    "                text=\"Generate underlying data table of the figure below:\",\n",
    "                return_tensors=\"pt\",\n",
    "                font_path=font_path\n",
    "            )\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        predictions = model.generate(**inputs, max_new_tokens=512)\n",
    "        output = processor.decode(predictions[0], skip_special_tokens=True)\n",
    "\n",
    "        if chart_type in [\"dot\", \"horizontal_bar\", \"line\"]:\n",
    "            # Parse JSON output\n",
    "            data = json.loads(output)\n",
    "            print(data)\n",
    "            x_data_series = \";\".join([str(item['x']) for item in data])\n",
    "            y_data_series = \";\".join([str(item['y']) for item in data])\n",
    "        else:\n",
    "            # Handle default output format\n",
    "            df = display_deplot_output(output)\n",
    "            # Drop rows with NaN values\n",
    "            df = df.dropna()\n",
    "            x_data_series = \";\".join(df[df.columns[0]].astype(str))\n",
    "            y_data_series = \";\".join(df[df.columns[1]].astype(str))\n",
    "    except:\n",
    "        x_data_series = \"0\"\n",
    "        y_data_series = \"0\"\n",
    "\n",
    "    return x_data_series, y_data_series\n",
    "\n",
    "# Helper function to preprocess the image\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image = img_to_array(image) / 255.0\n",
    "    return np.expand_dims(image, axis=0)\n",
    "\n",
    "# Updated function to check if a series contains only floats\n",
    "def is_float_series(series):\n",
    "    try:\n",
    "        series = [float(item) for item in series.split(\";\")]\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8df2ed91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T12:43:29.741589Z",
     "iopub.status.busy": "2025-03-11T12:43:29.741379Z",
     "iopub.status.idle": "2025-03-11T12:43:29.747192Z",
     "shell.execute_reply": "2025-03-11T12:43:29.746547Z"
    },
    "papermill": {
     "duration": 0.010453,
     "end_time": "2025-03-11T12:43:29.748313",
     "exception": false,
     "start_time": "2025-03-11T12:43:29.737860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def is_invalid_number(value):\n",
    "    try:\n",
    "        n = float(value)\n",
    "        return np.isnan(n) or np.isinf(n)\n",
    "    except ValueError:\n",
    "        return True\n",
    "\n",
    "def clean_series(x_series, y_series, chart_type):\n",
    "    try:\n",
    "        x_values = x_series.split(\";\")\n",
    "        y_values = y_series.split(\";\")\n",
    "\n",
    "        # Check lengths match\n",
    "        if len(x_values) != len(y_values):\n",
    "            return \"0\", \"0\"\n",
    "\n",
    "        # Handle invalid values in x and y\n",
    "        for i in range(len(x_values)):\n",
    "            if chart_type in [\"vertical_bar\", \"line\", \"dot\"]:\n",
    "                # x is categorical, y is numeric\n",
    "                if is_invalid_number(y_values[i]):\n",
    "                    x_values[i] = \"0\"\n",
    "                    y_values[i] = \"0\"\n",
    "            elif chart_type == \"horizontal_bar\":\n",
    "                # x is numeric, y is categorical\n",
    "                if is_invalid_number(x_values[i]):\n",
    "                    x_values[i] = \"0\"\n",
    "                    y_values[i] = \"0\"\n",
    "            elif chart_type == \"scatter\":\n",
    "                # x and y are both numeric\n",
    "                if is_invalid_number(x_values[i]) or is_invalid_number(y_values[i]):\n",
    "                    x_values[i] = \"0\"\n",
    "                    y_values[i] = \"0\"\n",
    "\n",
    "        # Rejoin the series\n",
    "        cleaned_x_series = \";\".join(x_values)\n",
    "        cleaned_y_series = \";\".join(y_values)\n",
    "        return cleaned_x_series, cleaned_y_series\n",
    "\n",
    "    except Exception as e:\n",
    "        # If any unexpected error occurs, set both x and y to \"0\"\n",
    "        return \"0\", \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "780adfa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T12:43:29.755241Z",
     "iopub.status.busy": "2025-03-11T12:43:29.755035Z",
     "iopub.status.idle": "2025-03-11T12:44:24.846401Z",
     "shell.execute_reply": "2025-03-11T12:44:24.845476Z"
    },
    "papermill": {
     "duration": 55.096389,
     "end_time": "2025-03-11T12:44:24.847721",
     "exception": false,
     "start_time": "2025-03-11T12:43:29.751332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'x': '0', 'y': 0.0}, {'x': '6', 'y': -1.3353}, {'x': '12', 'y': -2.6353}, {'x': '18', 'y': -1.9653}, {'x': '24', 'y': -3.2753}]\n",
      "0;6;12;18;24\n",
      "0.0;-1.3353;-2.6353;-1.9653;-3.2753\n",
      " 21-Feb; 22-Feb; 23-Feb; 24-Feb; 25-Feb; 26-Feb; 27-Feb; 28-Feb; 29-Feb; 01-Mar; 02-Mar; 03-Mar; 04-Mar; 05-Mar; 06-Mar; 07-Mar; 08-Mar; 09-Mar; 10-Mar\n",
      "89000;151192;172700;177800;137500;99168;17242;41422;60168;66027;53941;44475;64653;79171;82392;102623;130650;101611;8283\n",
      "\n",
      "image 1/1 /kaggle/input/benetech-making-graphs-accessible/test/images/00f5404753cf.jpg: 480x640 1 plot, 75.3ms\n",
      "Speed: 10.2ms preprocess, 75.3ms inference, 90.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /kaggle/input/benetech-making-graphs-accessible/test/images/00f5404753cf.jpg: 480x640 5 x-ticks, 6 y-ticks, 6 x-tick-texts, 6 y-tick-texts, 1 xy-tick, 62.2ms\n",
      "Speed: 1.8ms preprocess, 62.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /kaggle/input/benetech-making-graphs-accessible/test/images/00f5404753cf.jpg: 608x800 39 scatter_points, 93.6ms\n",
      "Speed: 2.5ms preprocess, 93.6ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 800)\n",
      "4.9586;4.9911;4.9911;5.9642;5.9642;5.9642;6.9697;6.9697;6.9697;7.9753;7.9753;7.9753;8.9809;8.9809;8.9809;9.9864;9.9864;9.9864;10.9595;10.9920;10.9920;10.9920;11.9651;11.9651;11.9975;11.9975;11.9975;12.9706;12.9706;12.9706;13.9762;13.9762;13.9762;14.9818;14.9818;14.9818;15.9873;15.9873;15.9873\n",
      "14.1284;11.0092;12.0848;12.0848;13.1604;14.1284;14.1284;16.0645;17.0325;17.0325;18.1081;19.0761;20.0441;21.1197;22.0877;21.1197;22.0877;23.0557;24.1313;21.1197;22.0877;23.0557;25.2069;26.0673;23.0557;24.0237;25.0993;24.0237;26.0673;27.0354;25.0993;27.0354;28.1109;26.0673;27.0354;29.0790;29.0790;30.0470;31.0150\n",
      " Group 1; Group 2\n",
      "3.6;8.4\n",
      "[{'x': '0.0', 'y': 0.0132}, {'x': '0.4', 'y': 0.0132}, {'x': '0.8', 'y': 0.0132}, {'x': '1.2', 'y': 0.0132}, {'x': '1.6', 'y': 0.0132}, {'x': '2.0', 'y': 0.0132}, {'x': '2.4', 'y': 0.0132}, {'x': '2.8', 'y': 0.0132}]\n",
      "0.0;0.4;0.8;1.2;1.6;2.0;2.4;2.8\n",
      "0.0132;0.0132;0.0132;0.0132;0.0132;0.0132;0.0132;0.0132\n",
      "Results saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "# Use a working tokenizer\n",
    "processor = TrOCRProcessor.from_pretrained(\"/kaggle/input/trocr_model/other/default/1/trocr_model\")\n",
    "\n",
    "# Load the model from converted SafeTensors\n",
    "model_text = VisionEncoderDecoderModel.from_pretrained(\"/kaggle/input/trocr_model/other/default/1/trocr_model\").to(device)\n",
    "\n",
    "# Path to the folder with images and to font\n",
    "images_folder = \"/kaggle/input/benetech-making-graphs-accessible/test/images\"\n",
    "output_csv_path = \"submission.csv\"\n",
    "font_path = \"/kaggle/input/huruff/Arial.ttf\"\n",
    "\n",
    "# Dataframe to store results\n",
    "results = []\n",
    "\n",
    "# Iterate through images in the folder\n",
    "for img_name in os.listdir(images_folder):\n",
    "    img_path = os.path.join(images_folder, img_name)\n",
    "    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        base_name = os.path.splitext(img_name)[0]\n",
    "        \n",
    "        # Preprocess and predict chart type\n",
    "        image = preprocess_image(img_path)\n",
    "        predictions = model_Charttype.predict(image, verbose=0)\n",
    "        predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n",
    "        predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")\n",
    "\n",
    "        # Select model and processor based on chart type\n",
    "        if predicted_chart_type == \"horizontal_bar\":\n",
    "            selected_model = model_Deplot_horizontal\n",
    "            selected_processor = processor_horizontal\n",
    "        elif predicted_chart_type == \"line\":\n",
    "            selected_model = model_Deplot_line\n",
    "            selected_processor = processor_line\n",
    "        elif predicted_chart_type == \"dot\":\n",
    "            selected_model = model_Deplot_dot\n",
    "            selected_processor = processor_dot\n",
    "        elif predicted_chart_type==\"scatter\":\n",
    "            selected_model = model_text\n",
    "            selected_processor = processor\n",
    "        else:\n",
    "            selected_model = model_Deplot\n",
    "            selected_processor = processor_Deplot\n",
    "        \n",
    "        if(predicted_chart_type!=\"scatter\"):\n",
    "            # Use deplot to extract data\n",
    "            x_data_series, y_data_series = deplot_with_model(\n",
    "                img_path, selected_model, selected_processor, device, font_path, predicted_chart_type\n",
    "            )\n",
    "        else:\n",
    "            # **Run YOLO inference for plot area**\n",
    "            plot_results = plot_model(img_path)\n",
    "            plot_x1, plot_y1, plot_x2, plot_y2 = None, None, None, None\n",
    "            for box in plot_results[0].boxes:\n",
    "                plot_x1, plot_y1, plot_x2, plot_y2 = map(int, box.xyxy[0])  # Get bounding box of the detected plot\n",
    "            \n",
    "            # Load image\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            img_h, img_w,_ = image.shape\n",
    "            \n",
    "            # Run YOLO inference for ticks\n",
    "            tick_results = tick_model(img_path)\n",
    "            \n",
    "            # Store detected elements\n",
    "            tick_positions_x = []  # (image_x, plot_x_value)\n",
    "            tick_positions_y = []  # (image_y, plot_y_value)\n",
    "            \n",
    "            # Text box positions & recognized values\n",
    "            text_boxes_x = []  # X-axis text positions\n",
    "            text_boxes_y = []  # Y-axis text positions\n",
    "            \n",
    "            for box in tick_results[0].boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                class_id = int(box.cls[0])  # 0=x-tick, 1=y-tick, 2=x-text, 3=y-text, 4=xy-tick\n",
    "            \n",
    "                if class_id in [2, 3]:  # If it's a text box, recognize text\n",
    "                    cropped_text = image[y1:y2, x1:x2]\n",
    "                    pil_crop = Image.fromarray(cropped_text)\n",
    "            \n",
    "                    # Process for TrOCR\n",
    "                    pixel_values = selected_processor(pil_crop, return_tensors=\"pt\").pixel_values.to(device)\n",
    "            \n",
    "                    # Predict text\n",
    "                    with torch.no_grad():\n",
    "                        generated_ids = model_text.generate(pixel_values)\n",
    "                        predicted_text = selected_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "            \n",
    "                    if class_id == 2:  # X-axis text\n",
    "                        text_boxes_x.append((x1, y1, x2, y2, predicted_text))\n",
    "                    elif class_id == 3:  # Y-axis text\n",
    "                        text_boxes_y.append((x1, y1, x2, y2, predicted_text))\n",
    "            \n",
    "                elif class_id in [0, 1, 4]:  # Tick marks\n",
    "                    center_x = (x1 + x2) // 2\n",
    "                    center_y = (y1 + y2) // 2\n",
    "                    if class_id == 0:  # X-axis tick\n",
    "                        tick_positions_x.append((center_x, center_y))\n",
    "                    elif class_id == 1: # Y-axis tick\n",
    "                        tick_positions_y.append((center_x, center_y))\n",
    "                    else:  \n",
    "                        tick_positions_x.append((center_x, center_y))\n",
    "                        tick_positions_y.append((center_x, center_y))\n",
    "\n",
    "            \n",
    "            # **Sort tick positions before matching**\n",
    "            tick_positions_x = sorted(tick_positions_x, key=lambda t: t[0])  # Sort X-ticks by center_x\n",
    "            tick_positions_y = sorted(tick_positions_y, key=lambda t: t[1], reverse=True)  # Sort Y-ticks by center_y\n",
    "\n",
    "            # **Sort text boxes before matching**\n",
    "            text_boxes_x = sorted(text_boxes_x, key=lambda t: t[0])  # Sort by X-position (left to right)\n",
    "            text_boxes_y = sorted(text_boxes_y, key=lambda t: t[1], reverse=True)  # Sort by Y-position (bottom to top)\n",
    "            \n",
    "            # **Match text to nearest tick positions**\n",
    "            def match_ticks_to_text(tick_positions, text_boxes):\n",
    "                matched_ticks = []\n",
    "                used_ticks = set()  # To prevent assigning the same tick multiple times\n",
    "            \n",
    "                for text_box in text_boxes:\n",
    "                    x1, y1, x2, y2, text_value = text_box\n",
    "                    text_center_x = (x1 + x2) // 2\n",
    "                    text_center_y = (y1 + y2) // 2\n",
    "\n",
    "                    # Skip if text_value is missing or invalid\n",
    "                    if not text_value.strip():  # If text is empty or only whitespace\n",
    "                        continue\n",
    "            \n",
    "                    # Find the closest tick using Euclidean distance\n",
    "                    closest_tick = None\n",
    "                    min_distance = float(\"inf\")\n",
    "            \n",
    "                    for tick_pos in tick_positions:\n",
    "                        tick_x, tick_y = tick_pos\n",
    "                        distance = np.sqrt((text_center_x - tick_x) ** 2 + (text_center_y - tick_y) ** 2)\n",
    "            \n",
    "                        if distance < min_distance and tick_pos not in used_ticks:\n",
    "                            min_distance = distance\n",
    "                            closest_tick = tick_pos\n",
    "            \n",
    "                    if closest_tick:\n",
    "                        try:\n",
    "                            plot_value = float(text_value)  # Convert to float\n",
    "                            matched_ticks.append((closest_tick, plot_value))\n",
    "                            used_ticks.add(closest_tick)  # Mark tick as used\n",
    "                        except ValueError:\n",
    "                            continue  # Skip invalid text values\n",
    "                        \n",
    "                return matched_ticks\n",
    "            \n",
    "            # Get matched tick values\n",
    "            x_axis_values = match_ticks_to_text(tick_positions_x, text_boxes_x)\n",
    "            y_axis_values = match_ticks_to_text(tick_positions_y, text_boxes_y)\n",
    "\n",
    "            if(len(x_axis_values)==0 or len(y_axis_values)==0):\n",
    "                x_data_series = \"0\"\n",
    "                y_data_series = \"0\"\n",
    "                x_data_series, y_data_series = clean_series(x_data_series, y_data_series, predicted_chart_type)\n",
    "                results.append({\"id\": f\"{base_name}_x\", \"data_series\": x_data_series, \"chart_type\": predicted_chart_type})\n",
    "                results.append({\"id\": f\"{base_name}_y\", \"data_series\": y_data_series, \"chart_type\": predicted_chart_type})\n",
    "                continue\n",
    "\n",
    "            \n",
    "            # Keep only the first number from the inner tuple in x_axis_values\n",
    "            x_axis_values = [(t[0][0], t[1]) for t in x_axis_values]\n",
    "            \n",
    "            # Keep only the second number from the inner tuple in y_axis_values\n",
    "            y_axis_values = [(t[0][1], t[1]) for t in y_axis_values]\n",
    "            \n",
    "            # Define a margin (in pixels) for tolerance\n",
    "            MARGIN = 5  # You can adjust this value based on your specific requirements\n",
    "            \n",
    "            # Extract only the plot values (with margin for error)\n",
    "            x_img, x_plot = zip(*x_axis_values) if x_axis_values else ([], [])\n",
    "            y_img, y_plot = zip(*y_axis_values) if y_axis_values else ([], [])\n",
    "\n",
    "            # Apply margin for tolerance when extracting plot values\n",
    "            if x_img and x_plot:\n",
    "                x_min, x_max = min(x_img) - MARGIN, max(x_img) + MARGIN\n",
    "                x_img = [x for x in x_img if x_min <= x <= x_max]  # Apply margin filter\n",
    "                x_plot = [x_plot[i] for i in range(len(x_plot)) if x_min <= x_img[i] <= x_max]  # Filter matching values\n",
    "            \n",
    "            if y_img and y_plot:\n",
    "                y_min, y_max = min(y_img) - MARGIN, max(y_img) + MARGIN\n",
    "                y_img = [y for y in y_img if y_min <= y <= y_max]  # Apply margin filter\n",
    "                y_plot = [y_plot[i] for i in range(len(y_plot)) if y_min <= y_img[i] <= y_max]  # Filter matching values\n",
    "\n",
    "\n",
    "            def fix_incorrect_values(axis_values, tolerance=1.5, max_iterations=20):\n",
    "                \"\"\"\n",
    "                Fix incorrect values in axis data by checking for regular spacing and applying a tolerance range.\n",
    "                \n",
    "                Args:\n",
    "                axis_values (list): List of values for X or Y axis.\n",
    "                tolerance (float): Tolerance range for how much a value can deviate from regular spacing.\n",
    "                max_iterations (int): Maximum iterations to prevent infinite loops.\n",
    "                \n",
    "                Returns:\n",
    "                list: Corrected axis values.\n",
    "                \"\"\"\n",
    "                if len(axis_values) < 3:\n",
    "                    return axis_values  # Can't fix with less than 3 values\n",
    "            \n",
    "                diffs = [axis_values[i+1] - axis_values[i] for i in range(len(axis_values)-1)]\n",
    "                spacing = np.median(diffs)  # Use median to handle outliers in spacing\n",
    "                corrected_values = axis_values.copy()\n",
    "                \n",
    "                for _ in range(max_iterations):\n",
    "                    corrected = False\n",
    "                    for i in range(1, len(corrected_values) - 1):\n",
    "                        expected_value = corrected_values[i - 1] + spacing\n",
    "                        if abs(corrected_values[i] - expected_value) > spacing * tolerance:\n",
    "                            corrected_values[i] = expected_value  # Fix the value\n",
    "                            corrected = True\n",
    "                    \n",
    "                    if not corrected:\n",
    "                        break  # Stop if no changes were made in this iteration\n",
    "                \n",
    "                return corrected_values\n",
    "            \n",
    "            # Fix the x and y axis values if needed\n",
    "            x_plot_corrected = fix_incorrect_values(x_plot, tolerance=1.5)\n",
    "            y_plot_corrected = fix_incorrect_values(y_plot, tolerance=1.5)\n",
    "\n",
    "            # **Fit linear transformation for x and y**\n",
    "            #x_transform = np.poly1d(np.polyfit(x_img, x_plot, 1)) if len(x_img) > 1 else lambda x: x\n",
    "            #y_transform = np.poly1d(np.polyfit(y_img, y_plot, 1)) if len(y_img) > 1 else lambda y: y\n",
    "\n",
    "            import numpy as np\n",
    "            from sklearn.linear_model import RANSACRegressor\n",
    "            from sklearn.preprocessing import PolynomialFeatures\n",
    "            from sklearn.pipeline import make_pipeline\n",
    "            \n",
    "            # --- Robust regression for the x-axis transformation ---\n",
    "            try:\n",
    "                if len(x_img) > 1:\n",
    "                    model_x = make_pipeline(PolynomialFeatures(degree=1), RANSACRegressor())\n",
    "                    model_x.fit(np.array(x_img).reshape(-1, 1), np.array(x_plot_corrected))\n",
    "                    transform_x = lambda x: model_x.predict(np.array([[x]]))[0]\n",
    "                else:\n",
    "                    transform_x = lambda x: x\n",
    "            except Exception as e:\n",
    "                print(\"Error in RANSAC for x, falling back to polyfit: \", e)\n",
    "                if len(x_img) > 1:\n",
    "                    coeffs = np.polyfit(x_img, x_plot_corrected, 1)\n",
    "                    transform_x = np.poly1d(coeffs)\n",
    "                else:\n",
    "                    transform_x = lambda x: x\n",
    "            \n",
    "            # --- Robust regression for the y-axis transformation ---\n",
    "            try:\n",
    "                if len(y_img) > 1:\n",
    "                    model_y = make_pipeline(PolynomialFeatures(degree=1), RANSACRegressor())\n",
    "                    model_y.fit(np.array(y_img).reshape(-1, 1), np.array(y_plot_corrected))\n",
    "                    transform_y = lambda y: model_y.predict(np.array([[y]]))[0]\n",
    "                else:\n",
    "                    transform_y = lambda y: y\n",
    "            except Exception as e:\n",
    "                print(\"Error in RANSAC for y, falling back to polyfit: \", e)\n",
    "                if len(y_img) > 1:\n",
    "                    coeffs = np.polyfit(y_img, y_plot_corrected, 1)\n",
    "                    transform_y = np.poly1d(coeffs)\n",
    "                else:\n",
    "                    transform_y = lambda y: y\n",
    "            \n",
    "            def transform_point(x, y):\n",
    "                return transform_x(x), transform_y(y)\n",
    "            \n",
    "            # --- Run YOLO inference for scatter points ---\n",
    "            scatter_results = scatter_model(img_path)  # Ensure this call is made!\n",
    "            \n",
    "            # --- Extract scatter positions & transform them to plot space ---\n",
    "            scatter_plot_coords = []\n",
    "            for box in scatter_results[0].boxes:\n",
    "                try:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                except Exception as e:\n",
    "                    print(\"Error processing box coordinates: \", e)\n",
    "                    continue\n",
    "                center_x = (x1 + x2) // 2\n",
    "                center_y = (y1 + y2) // 2\n",
    "            \n",
    "                # Remove scatter points outside the detected plot area\n",
    "                if plot_x1 and plot_y1 and plot_x2 and plot_y2:\n",
    "                    if not (plot_x1 <= center_x <= plot_x2 and plot_y1 <= center_y <= plot_y2):\n",
    "                        continue\n",
    "            \n",
    "                try:\n",
    "                    plot_x, plot_y = transform_point(center_x, center_y)\n",
    "                    scatter_plot_coords.append((plot_x, plot_y))\n",
    "                except Exception as e:\n",
    "                    print(\"Error transforming scatter point: \", e)\n",
    "                    continue\n",
    "            \n",
    "            # --- Sort scatter points: first by x-value, then by y-value if x is the same ---\n",
    "            scatter_plot_coords = sorted(scatter_plot_coords, key=lambda p: (p[0], p[1]))\n",
    "            \n",
    "            # Extract x and y values\n",
    "            #x_data_series = \";\".join(str(x) for x, _ in scatter_plot_coords)\n",
    "            #y_data_series = \";\".join(str(y) for _, y in scatter_plot_coords)\n",
    "\n",
    "            # Extract x and y values with 4 number after point\n",
    "            x_data_series = \";\".join(f\"{x:.4f}\" for x, _ in scatter_plot_coords)\n",
    "            y_data_series = \";\".join(f\"{y:.4f}\" for _, y in scatter_plot_coords)\n",
    "\n",
    "        \n",
    "        if(x_data_series==None or len(x_data_series)==0):\n",
    "            x_data_series = \"0\"\n",
    "        if(y_data_series==None or len(y_data_series)==0):\n",
    "            y_data_series = \"0\"\n",
    "        print(x_data_series)\n",
    "        print(y_data_series)\n",
    "        x_data_series,y_data_series = clean_series(x_data_series, y_data_series, predicted_chart_type)\n",
    "        results.append({\n",
    "            \"id\": f\"{base_name}_x\",\n",
    "            \"data_series\": x_data_series,\n",
    "            \"chart_type\": predicted_chart_type\n",
    "        })\n",
    "        results.append({\n",
    "            \"id\": f\"{base_name}_y\",\n",
    "            \"data_series\": y_data_series,\n",
    "            \"chart_type\": predicted_chart_type\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#Save results to CSV\n",
    "submission = pd.DataFrame(results)\n",
    "submission.to_csv(output_csv_path, index=False)\n",
    "print(f\"Results saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd333540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T12:44:24.856401Z",
     "iopub.status.busy": "2025-03-11T12:44:24.856163Z",
     "iopub.status.idle": "2025-03-11T12:44:24.867613Z",
     "shell.execute_reply": "2025-03-11T12:44:24.866711Z"
    },
    "papermill": {
     "duration": 0.01697,
     "end_time": "2025-03-11T12:44:24.868779",
     "exception": false,
     "start_time": "2025-03-11T12:44:24.851809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data_series</th>\n",
       "      <th>chart_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000b92c3b098_x</td>\n",
       "      <td>0;6;12;18;24</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000b92c3b098_y</td>\n",
       "      <td>0.0;-1.3353;-2.6353;-1.9653;-3.2753</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01b45b831589_x</td>\n",
       "      <td>21-Feb; 22-Feb; 23-Feb; 24-Feb; 25-Feb; 26-Fe...</td>\n",
       "      <td>vertical_bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01b45b831589_y</td>\n",
       "      <td>89000;151192;172700;177800;137500;99168;17242;...</td>\n",
       "      <td>vertical_bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00f5404753cf_x</td>\n",
       "      <td>4.9586;4.9911;4.9911;5.9642;5.9642;5.9642;6.96...</td>\n",
       "      <td>scatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00f5404753cf_y</td>\n",
       "      <td>14.1284;11.0092;12.0848;12.0848;13.1604;14.128...</td>\n",
       "      <td>scatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00dcf883a459_x</td>\n",
       "      <td>Group 1; Group 2</td>\n",
       "      <td>vertical_bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00dcf883a459_y</td>\n",
       "      <td>3.6;8.4</td>\n",
       "      <td>vertical_bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>007a18eb4e09_x</td>\n",
       "      <td>0.0;0.4;0.8;1.2;1.6;2.0;2.4;2.8</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>007a18eb4e09_y</td>\n",
       "      <td>0.0132;0.0132;0.0132;0.0132;0.0132;0.0132;0.01...</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                        data_series  \\\n",
       "0  000b92c3b098_x                                       0;6;12;18;24   \n",
       "1  000b92c3b098_y                0.0;-1.3353;-2.6353;-1.9653;-3.2753   \n",
       "2  01b45b831589_x   21-Feb; 22-Feb; 23-Feb; 24-Feb; 25-Feb; 26-Fe...   \n",
       "3  01b45b831589_y  89000;151192;172700;177800;137500;99168;17242;...   \n",
       "4  00f5404753cf_x  4.9586;4.9911;4.9911;5.9642;5.9642;5.9642;6.96...   \n",
       "5  00f5404753cf_y  14.1284;11.0092;12.0848;12.0848;13.1604;14.128...   \n",
       "6  00dcf883a459_x                                   Group 1; Group 2   \n",
       "7  00dcf883a459_y                                            3.6;8.4   \n",
       "8  007a18eb4e09_x                    0.0;0.4;0.8;1.2;1.6;2.0;2.4;2.8   \n",
       "9  007a18eb4e09_y  0.0132;0.0132;0.0132;0.0132;0.0132;0.0132;0.01...   \n",
       "\n",
       "     chart_type  \n",
       "0          line  \n",
       "1          line  \n",
       "2  vertical_bar  \n",
       "3  vertical_bar  \n",
       "4       scatter  \n",
       "5       scatter  \n",
       "6  vertical_bar  \n",
       "7  vertical_bar  \n",
       "8          line  \n",
       "9          line  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 5585780,
     "sourceId": 43873,
     "sourceType": "competition"
    },
    {
     "datasetId": 6209817,
     "sourceId": 10075894,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6288189,
     "sourceId": 10179974,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6446155,
     "sourceId": 10402947,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6458427,
     "sourceId": 10420340,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6463135,
     "sourceId": 10442039,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6682608,
     "sourceId": 10771831,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6683950,
     "sourceId": 10773534,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 1378,
     "modelInstanceId": 3437,
     "sourceId": 4647,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 189050,
     "modelInstanceId": 166730,
     "sourceId": 195535,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 244360,
     "modelInstanceId": 222598,
     "sourceId": 260375,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 244807,
     "modelInstanceId": 223045,
     "sourceId": 260890,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 246338,
     "modelInstanceId": 224589,
     "sourceId": 281041,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 244637,
     "modelInstanceId": 222878,
     "sourceId": 263513,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 156.949311,
   "end_time": "2025-03-11T12:44:28.133814",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-11T12:41:51.184503",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
