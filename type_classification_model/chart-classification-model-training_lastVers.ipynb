{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fadfb90",
   "metadata": {
    "papermill": {
     "duration": 0.00446,
     "end_time": "2025-04-04T15:17:58.263560",
     "exception": false,
     "start_time": "2025-04-04T15:17:58.259100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **upload and save resnet50 model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74624ed2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-04T15:17:58.271846Z",
     "iopub.status.busy": "2025-04-04T15:17:58.271609Z",
     "iopub.status.idle": "2025-04-04T15:18:12.073834Z",
     "shell.execute_reply": "2025-04-04T15:18:12.073096Z"
    },
    "papermill": {
     "duration": 13.808026,
     "end_time": "2025-04-04T15:18:12.075477",
     "exception": false,
     "start_time": "2025-04-04T15:17:58.267451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "#save resnet model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)  # Add a dropout layer with 50% dropout rate\n",
    "output = Dense(5, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.save('resnet50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187295e1",
   "metadata": {
    "papermill": {
     "duration": 0.004503,
     "end_time": "2025-04-04T15:18:12.085075",
     "exception": false,
     "start_time": "2025-04-04T15:18:12.080572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **train the first model for predict type of the chart**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42330c6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T15:18:12.095362Z",
     "iopub.status.busy": "2025-04-04T15:18:12.094933Z",
     "iopub.status.idle": "2025-04-04T15:30:19.438258Z",
     "shell.execute_reply": "2025-04-04T15:30:19.437522Z"
    },
    "papermill": {
     "duration": 727.349728,
     "end_time": "2025-04-04T15:30:19.439454",
     "exception": false,
     "start_time": "2025-04-04T15:18:12.089726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 546ms/step - accuracy: 0.9061 - loss: 0.3802 - val_accuracy: 0.2031 - val_loss: 1.7457\n",
      "Epoch 2/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 351ms/step - accuracy: 0.9754 - loss: 0.1463 - val_accuracy: 0.2051 - val_loss: 1.6088\n",
      "Epoch 3/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 312ms/step - accuracy: 0.9807 - loss: 0.0775 - val_accuracy: 0.1506 - val_loss: 1.6275\n",
      "Epoch 4/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 328ms/step - accuracy: 0.9878 - loss: 0.0436 - val_accuracy: 0.2340 - val_loss: 1.5921\n",
      "Epoch 5/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 325ms/step - accuracy: 0.9879 - loss: 0.0557 - val_accuracy: 0.3013 - val_loss: 3.6471\n",
      "Epoch 1/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 510ms/step - accuracy: 0.9896 - loss: 0.0443 - val_accuracy: 0.5052 - val_loss: 1.1076\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 365ms/step - accuracy: 0.9891 - loss: 0.0421 - val_accuracy: 0.7318 - val_loss: 0.8319\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 305ms/step - accuracy: 0.9929 - loss: 0.0434 - val_accuracy: 0.9626 - val_loss: 0.1802\n",
      "Epoch 4/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 331ms/step - accuracy: 0.9895 - loss: 0.0448 - val_accuracy: 0.9915 - val_loss: 0.0625\n",
      "Epoch 5/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 331ms/step - accuracy: 0.9922 - loss: 0.0294 - val_accuracy: 0.9936 - val_loss: 0.0340\n",
      "Epoch 6/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 308ms/step - accuracy: 0.9959 - loss: 0.0217 - val_accuracy: 0.9936 - val_loss: 0.0262\n",
      "Epoch 7/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 318ms/step - accuracy: 0.9897 - loss: 0.0336 - val_accuracy: 0.9947 - val_loss: 0.0219\n",
      "Epoch 8/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 307ms/step - accuracy: 0.9917 - loss: 0.0338 - val_accuracy: 0.9957 - val_loss: 0.0207\n",
      "Epoch 9/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 307ms/step - accuracy: 0.9945 - loss: 0.0182 - val_accuracy: 0.9957 - val_loss: 0.0204\n",
      "Epoch 10/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 310ms/step - accuracy: 0.9902 - loss: 0.0362 - val_accuracy: 0.9957 - val_loss: 0.0200\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.9972 - loss: 0.0163\n",
      "Validation Accuracy: 1.00, Validation Loss: 0.02\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# More Horizontal Data Paths\n",
    "hrz_images_dir = '/kaggle/input/sortrd-chart-data/selected_images_archive'\n",
    "hrz_annotations_dir = '/kaggle/input/sortrd-chart-data/json_files/json_files'\n",
    "\n",
    "dot_images_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/dot/images'\n",
    "dot_annotations_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/dot/annotations'\n",
    "\n",
    "line_images_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/line/images'\n",
    "line_annotations_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/line/annotations'\n",
    "\n",
    "scatter_images_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/scatter/images'\n",
    "scatter_annotations_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/scatter/annotations'\n",
    "\n",
    "vrt_images_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/vertical_bar/images'\n",
    "vrt_annotations_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/vertical_bar/annotations'\n",
    "\n",
    "files_paths = [\n",
    "    [hrz_images_dir,hrz_annotations_dir],\n",
    "    [dot_images_dir,dot_annotations_dir],\n",
    "    [line_images_dir,line_annotations_dir],\n",
    "    [scatter_images_dir,scatter_annotations_dir],\n",
    "    [vrt_images_dir,vrt_annotations_dir]\n",
    "]\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_data(files_paths):\n",
    "    image_paths, labels = [], []\n",
    "    chart_types = {\n",
    "        \"horizontal_bar\": 0,\n",
    "        \"vertical_bar\": 1,\n",
    "        \"dot\": 2,\n",
    "        \"line\": 3,\n",
    "        \"scatter\": 4\n",
    "    }\n",
    "    max_iterations = 2000\n",
    "    for charttype in files_paths:\n",
    "        iteration_count = 0\n",
    "        for filename in os.listdir(charttype[0]):\n",
    "            if iteration_count >= max_iterations:\n",
    "                break\n",
    "            if filename.endswith('.jpg'):\n",
    "                img_path = os.path.join(charttype[0], filename)\n",
    "                json_path = os.path.join(charttype[1], filename.replace('.jpg', '.json'))\n",
    "                \n",
    "                with open(json_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    chart_type = data.get('chart-type', None)\n",
    "                    \n",
    "                    # Handle missing or unknown chart types\n",
    "                    if chart_type not in chart_types:\n",
    "                        print(f\"Unknown chart type '{chart_type}' in {json_path}\")\n",
    "                        continue\n",
    "                    \n",
    "                    label = chart_types[chart_type]\n",
    "                    image_paths.append(img_path)\n",
    "                    labels.append(label)\n",
    "            iteration_count += 1\n",
    "    return image_paths, labels\n",
    "    \n",
    "# Preprocess images\n",
    "def preprocess_image(img_path, label, img_size=(224, 224)):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, img_size)\n",
    "    img = img / 255.0\n",
    "    return img, label\n",
    "\n",
    "# Load dataset\n",
    "image_paths, labels = load_data(files_paths)\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(image_paths, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Use a smaller subset of the training dataset for faster training\n",
    "train_paths = train_paths[:5000]  # Use only 5000 images for training\n",
    "train_labels = train_labels[:5000]  # Match train labels with train paths\n",
    "val_paths = val_paths[:1000]      # Use only 1000 images for validation\n",
    "val_labels = val_labels[:1000]    # Match validation labels with validation paths\n",
    "\n",
    "# Compute class weights to handle imbalance\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "train_dataset = train_dataset.map(lambda x, y: preprocess_image(x, y)).batch(32).shuffle(1000).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "val_dataset = val_dataset.map(lambda x, y: preprocess_image(x, y)).batch(32).repeat()\n",
    "\n",
    "# Define the model\n",
    "model = load_model('/kaggle/working/resnet50.h5')\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Train the model with limited steps per epoch\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    steps_per_epoch=100,  # Use only 100 batches per epoch\n",
    "    validation_steps=30,  # Use only 30 batches for validation\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Unfreeze top layers for fine-tuning\n",
    "for layer in base_model.layers[:-10]:  # Freeze all layers except the last 10\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model for fine-tuning\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-6), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    steps_per_epoch=100,\n",
    "    validation_steps=30,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('chart_classification_model.h5')\n",
    "\n",
    "# Evaluate on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_dataset, steps=30)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2f}, Validation Loss: {val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21468d20",
   "metadata": {
    "papermill": {
     "duration": 0.072775,
     "end_time": "2025-04-04T15:30:19.588593",
     "exception": false,
     "start_time": "2025-04-04T15:30:19.515818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Load original train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d319b9dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T15:30:19.735107Z",
     "iopub.status.busy": "2025-04-04T15:30:19.734766Z",
     "iopub.status.idle": "2025-04-04T15:30:19.740506Z",
     "shell.execute_reply": "2025-04-04T15:30:19.739788Z"
    },
    "papermill": {
     "duration": 0.080333,
     "end_time": "2025-04-04T15:30:19.741592",
     "exception": false,
     "start_time": "2025-04-04T15:30:19.661259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#paths\n",
    "images_dir = '/kaggle/input/benetech-making-graphs-accessible/train/images'\n",
    "annotations_dir = '/kaggle/input/benetech-making-graphs-accessible/train/annotations'\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_data(images_dir,annotations_dir):\n",
    "    image_paths, labels = [], []\n",
    "    chart_types = {\n",
    "        \"horizontal_bar\": 0,\n",
    "        \"vertical_bar\": 1,\n",
    "        \"dot\": 2,\n",
    "        \"line\": 3,\n",
    "        \"scatter\": 4\n",
    "    }\n",
    "    for filename in os.listdir(images_dir):\n",
    "        if iteration_count >= max_iterations:\n",
    "            break\n",
    "        if filename.endswith('.jpg'):\n",
    "            img_path = os.path.join(images_dir, filename)\n",
    "            json_path = os.path.join(annotations_dir, filename.replace('.jpg', '.json'))\n",
    "                \n",
    "            with open(json_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                chart_type = data.get('chart-type', None)\n",
    "                    \n",
    "                # Handle missing or unknown chart types\n",
    "                if chart_type not in chart_types:\n",
    "                    print(f\"Unknown chart type '{chart_type}' in {json_path}\")\n",
    "                    continue\n",
    "                    \n",
    "                label = chart_types[chart_type]\n",
    "                image_paths.append(img_path)\n",
    "                labels.append(label)\n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6065b29",
   "metadata": {
    "papermill": {
     "duration": 0.072703,
     "end_time": "2025-04-04T15:30:19.886365",
     "exception": false,
     "start_time": "2025-04-04T15:30:19.813662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **check the model on all of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2a4cc3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T15:30:20.033552Z",
     "iopub.status.busy": "2025-04-04T15:30:20.033314Z",
     "iopub.status.idle": "2025-04-04T16:53:34.068189Z",
     "shell.execute_reply": "2025-04-04T16:53:34.067131Z"
    },
    "papermill": {
     "duration": 4994.11107,
     "end_time": "2025-04-04T16:53:34.070032",
     "exception": false,
     "start_time": "2025-04-04T15:30:19.958962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60578 accuracy=99.01%\n",
      "Accuracy: 99.01% (59981/60578 correctly classified)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Paths\n",
    "model_path = \"/kaggle/working/chart_classification_model.h5\"\n",
    "image_folder = \"/kaggle/input/benetech-making-graphs-accessible/train/images\"\n",
    "json_folder = \"/kaggle/input/benetech-making-graphs-accessible/train/annotations\"\n",
    "\n",
    "chart_types = {\n",
    "    0: \"horizontal_bar\",\n",
    "    1: \"vertical_bar\",\n",
    "    2: \"dot\",\n",
    "    3: \"line\",\n",
    "    4: \"scatter\"\n",
    "}\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Initialize variables\n",
    "correct_predictions = 0\n",
    "total_images = 0\n",
    "\n",
    "# Helper function to preprocess the image\n",
    "def preprocess_image(image_path, target_size=(224, 224)):  # Adjust target size based on your model\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image = img_to_array(image) / 255.0\n",
    "    return np.expand_dims(image, axis=0)\n",
    "\n",
    "# Iterate through images and JSON\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith('.jpg'):\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        json_path = os.path.join(json_folder, filename.replace('.jpg', '.json'))\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    chart_type = data.get(\"chart-type\")  # Adjust key if it's different\n",
    "    \n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "    \n",
    "    # Preprocess image\n",
    "    image = preprocess_image(img_path)\n",
    "    \n",
    "    # Predict chart type\n",
    "    predictions = model.predict(image,verbose = 0)\n",
    "    predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")  # Map number to string\n",
    "    \n",
    "    \n",
    "    # Compare prediction with ground truth\n",
    "    if predicted_chart_type == chart_type:\n",
    "        correct_predictions += 1\n",
    "    total_images += 1\n",
    "    accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "    sys.stdout.write(f\"\\r{total_images} accuracy={accuracy * 100:.2f}%\")\n",
    "    sys.stdout.flush()  # Flush to ensure the line is updated immediately\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_images} correctly classified)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776e65b",
   "metadata": {
    "papermill": {
     "duration": 2.877944,
     "end_time": "2025-04-04T16:53:39.883665",
     "exception": false,
     "start_time": "2025-04-04T16:53:37.005721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Finetuning the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d05d1b85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T16:53:45.631875Z",
     "iopub.status.busy": "2025-04-04T16:53:45.631579Z",
     "iopub.status.idle": "2025-04-04T18:01:24.175635Z",
     "shell.execute_reply": "2025-04-04T18:01:24.174793Z"
    },
    "papermill": {
     "duration": 4062.102915,
     "end_time": "2025-04-04T18:01:24.921459",
     "exception": false,
     "start_time": "2025-04-04T16:53:42.818544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 134ms/step - accuracy: 0.9807 - loss: 0.0656 - val_accuracy: 0.9885 - val_loss: 0.0363\n",
      "Epoch 2/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 132ms/step - accuracy: 0.9922 - loss: 0.0221 - val_accuracy: 0.9918 - val_loss: 0.0292\n",
      "Epoch 3/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 132ms/step - accuracy: 0.9939 - loss: 0.0204 - val_accuracy: 0.9931 - val_loss: 0.0217\n",
      "Epoch 4/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 133ms/step - accuracy: 0.9974 - loss: 0.0081 - val_accuracy: 0.9929 - val_loss: 0.0218\n",
      "Epoch 5/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 131ms/step - accuracy: 0.9979 - loss: 0.0059 - val_accuracy: 0.9929 - val_loss: 0.0205\n",
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 329ms/step - accuracy: 0.9152 - loss: 1.0175 - val_accuracy: 0.9831 - val_loss: 0.0693\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 327ms/step - accuracy: 0.9707 - loss: 0.3978 - val_accuracy: 0.9909 - val_loss: 0.0297\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 327ms/step - accuracy: 0.9821 - loss: 0.2310 - val_accuracy: 0.9913 - val_loss: 0.0198\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 329ms/step - accuracy: 0.9864 - loss: 0.1469 - val_accuracy: 0.9929 - val_loss: 0.0139\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 328ms/step - accuracy: 0.9900 - loss: 0.0878 - val_accuracy: 0.9965 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 327ms/step - accuracy: 0.9914 - loss: 0.1032 - val_accuracy: 0.9972 - val_loss: 0.0084\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 329ms/step - accuracy: 0.9935 - loss: 0.0548 - val_accuracy: 0.9975 - val_loss: 0.0073\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 327ms/step - accuracy: 0.9948 - loss: 0.0377 - val_accuracy: 0.9980 - val_loss: 0.0075\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 327ms/step - accuracy: 0.9957 - loss: 0.0352 - val_accuracy: 0.9986 - val_loss: 0.0060\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 328ms/step - accuracy: 0.9963 - loss: 0.0208 - val_accuracy: 0.9985 - val_loss: 0.0058\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.9975 - loss: 0.0070\n",
      "Validation Accuracy: 1.00, Validation Loss: 0.01\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths to the sorted data folders\n",
    "data_paths = {\n",
    "    \"horizontal_bar\": \"/kaggle/input/benetech-extra-generated-data/graphs_h\",\n",
    "    \"vertical_bar\": \"/kaggle/input/benetech-extra-generated-data/graphs_v\",\n",
    "    \"dot\": \"/kaggle/input/benetech-extra-generated-data/graphs_d\",\n",
    "    \"line\": \"/kaggle/input/benetech-extra-generated-data/graphs_l\",\n",
    "    \"scatter\": \"/kaggle/input/benetech-extra-generated-data/graphs_s\"\n",
    "}\n",
    "\n",
    "# Labels for each folder\n",
    "chart_types = {\n",
    "    \"horizontal_bar\": 0,\n",
    "    \"vertical_bar\": 1,\n",
    "    \"dot\": 2,\n",
    "    \"line\": 3,\n",
    "    \"scatter\": 4\n",
    "}\n",
    "max_chart = {\n",
    "    \"horizontal_bar\":3000,\n",
    "    \"vertical_bar\": 1400,\n",
    "    \"dot\": 1400,\n",
    "    \"line\": 3000,\n",
    "    \"scatter\": 1400\n",
    "}\n",
    "\n",
    "# Function to load and label images\n",
    "def load_images(data_paths, chart_types, max_images_per_class=2000):\n",
    "    image_paths, labels = [], []\n",
    "    for chart_type, path in data_paths.items():\n",
    "        files = os.listdir(path)\n",
    "        random.shuffle(files)\n",
    "        for i, filename in enumerate(files):\n",
    "            if i >= max_chart[chart_type]:  # Limit to max_images_per_class per folder\n",
    "                break\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png'):  # Support common image formats\n",
    "                image_paths.append(os.path.join(path, filename))\n",
    "                labels.append(chart_types[chart_type])\n",
    "    image_paths, labels = shuffle(image_paths, labels, random_state=0)\n",
    "    return image_paths, labels\n",
    "\n",
    "# Load and label the images\n",
    "image_paths, labels = load_images(data_paths, chart_types)\n",
    "\n",
    "# Shuffle the data\n",
    "data = list(zip(image_paths, labels))\n",
    "np.random.shuffle(data)\n",
    "image_paths, labels = zip(*data)\n",
    "\n",
    "# Preprocess images\n",
    "def preprocess_image(img_path, label, img_size=(224, 224)):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, img_size)\n",
    "    img = img / 255.0\n",
    "    return img, label\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "train_dataset = train_dataset.map(lambda x, y: preprocess_image(x, y)).batch(32).shuffle(1000).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "val_dataset = val_dataset.map(lambda x, y: preprocess_image(x, y)).batch(32).repeat()\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = load_model('/kaggle/working/chart_classification_model.h5')\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in model.layers[:-10]:  # Freeze all layers except the last 10\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with limited steps per epoch\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    steps_per_epoch=1000,\n",
    "    validation_steps=300,\n",
    "    epochs=5\n",
    ")\n",
    "model.save('fine_tuned_chart_classification_model_mid_v3_5.h5')\n",
    "\n",
    "# Unfreeze all layers for fine-tuning\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model with a smaller learning rate for fine-tuning\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-6), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    steps_per_epoch=1000,\n",
    "    validation_steps=300,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save('fine_tuned_chart_classification_model_v3_5.h5')\n",
    "\n",
    "# Evaluate on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_dataset, steps=30)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2f}, Validation Loss: {val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa24d2e",
   "metadata": {
    "papermill": {
     "duration": 3.599848,
     "end_time": "2025-04-04T18:01:32.188869",
     "exception": false,
     "start_time": "2025-04-04T18:01:28.589021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **check the new model on all data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eceb75e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T18:01:39.469748Z",
     "iopub.status.busy": "2025-04-04T18:01:39.469353Z",
     "iopub.status.idle": "2025-04-04T19:15:11.576069Z",
     "shell.execute_reply": "2025-04-04T19:15:11.574952Z"
    },
    "papermill": {
     "duration": 4415.742262,
     "end_time": "2025-04-04T19:15:11.578256",
     "exception": false,
     "start_time": "2025-04-04T18:01:35.835994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60578 accuracy=97.15%\n",
      "Accuracy: 97.15% (58853/60578 correctly classified)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Paths\n",
    "model_path = \"fine_tuned_chart_classification_model_v3_5.h5\"\n",
    "image_folder = \"/kaggle/input/benetech-making-graphs-accessible/train/images\"\n",
    "json_folder = \"/kaggle/input/benetech-making-graphs-accessible/train/annotations\"\n",
    "\n",
    "chart_types = {\n",
    "    0: \"horizontal_bar\",\n",
    "    1: \"vertical_bar\",\n",
    "    2: \"dot\",\n",
    "    3: \"line\",\n",
    "    4: \"scatter\"\n",
    "}\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Initialize variables\n",
    "correct_predictions = 0\n",
    "total_images = 0\n",
    "\n",
    "# Helper function to preprocess the image\n",
    "def preprocess_image(image_path, target_size=(224, 224)):  # Adjust target size based on your model\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image = img_to_array(image) / 255.0\n",
    "    return np.expand_dims(image, axis=0)\n",
    "\n",
    "# Iterate through images and JSON\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith('.jpg'):\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        json_path = os.path.join(json_folder, filename.replace('.jpg', '.json'))\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    chart_type = data.get(\"chart-type\")  # Adjust key if it's different\n",
    "    \n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "    \n",
    "    # Preprocess image\n",
    "    image = preprocess_image(img_path)\n",
    "    \n",
    "    # Predict chart type\n",
    "    predictions = model.predict(image,verbose = 0)\n",
    "    predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")  # Map number to string\n",
    "    \n",
    "    \n",
    "    # Compare prediction with ground truth\n",
    "    if predicted_chart_type == chart_type:\n",
    "        correct_predictions += 1\n",
    "    total_images += 1\n",
    "    accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "    sys.stdout.write(f\"\\r{total_images} accuracy={accuracy * 100:.2f}%\")\n",
    "    sys.stdout.flush()  # Flush to ensure the line is updated immediately\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_images} correctly classified)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6492b26a",
   "metadata": {
    "papermill": {
     "duration": 6.618362,
     "end_time": "2025-04-04T19:15:24.733338",
     "exception": false,
     "start_time": "2025-04-04T19:15:18.114976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **check new model on each type of graph**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2ff39d",
   "metadata": {
    "papermill": {
     "duration": 6.472381,
     "end_time": "2025-04-04T19:15:37.932246",
     "exception": false,
     "start_time": "2025-04-04T19:15:31.459865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Horizontal bar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10746327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T19:15:51.033064Z",
     "iopub.status.busy": "2025-04-04T19:15:51.032703Z",
     "iopub.status.idle": "2025-04-04T19:16:00.305687Z",
     "shell.execute_reply": "2025-04-04T19:16:00.304782Z"
    },
    "papermill": {
     "duration": 16.030814,
     "end_time": "2025-04-04T19:16:00.306940",
     "exception": false,
     "start_time": "2025-04-04T19:15:44.276126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 accuracy=58.90%\n",
      "Accuracy: 58.90% (43/73 correctly classified)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Paths\n",
    "model_path = \"/kaggle/working/fine_tuned_chart_classification_model_v3_5.h5\"\n",
    "image_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/horizontal_bar/images\"\n",
    "json_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/horizontal_bar/annotations\"\n",
    "\n",
    "chart_types = {\n",
    "    0: \"horizontal_bar\",\n",
    "    1: \"vertical_bar\",\n",
    "    2: \"dot\",\n",
    "    3: \"line\",\n",
    "    4: \"scatter\"\n",
    "}\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Initialize variables\n",
    "correct_predictions = 0\n",
    "total_images = 0\n",
    "\n",
    "# Helper function to preprocess the image\n",
    "def preprocess_image(image_path, target_size=(224, 224)):  # Adjust target size based on your model\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image = img_to_array(image) / 255.0\n",
    "    return np.expand_dims(image, axis=0)\n",
    "\n",
    "# Iterate through images and JSON\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith('.jpg'):\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        json_path = os.path.join(json_folder, filename.replace('.jpg', '.json'))\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    chart_type = data.get(\"chart-type\")  # Adjust key if it's different\n",
    "    \n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "    \n",
    "    # Preprocess image\n",
    "    image = preprocess_image(img_path)\n",
    "    \n",
    "    # Predict chart type\n",
    "    predictions = model.predict(image,verbose = 0)\n",
    "    predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")  # Map number to string\n",
    "    \n",
    "    \n",
    "    # Compare prediction with ground truth\n",
    "    if predicted_chart_type == chart_type:\n",
    "        correct_predictions += 1\n",
    "    total_images += 1\n",
    "    accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "    sys.stdout.write(f\"\\r{total_images} accuracy={accuracy * 100:.2f}%\")\n",
    "    sys.stdout.flush()  # Flush to ensure the line is updated immediately\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_images} correctly classified)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acaf30e",
   "metadata": {
    "papermill": {
     "duration": 6.548141,
     "end_time": "2025-04-04T19:16:13.375347",
     "exception": false,
     "start_time": "2025-04-04T19:16:06.827206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**vertical bar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b164d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T19:16:26.561710Z",
     "iopub.status.busy": "2025-04-04T19:16:26.561273Z",
     "iopub.status.idle": "2025-04-04T19:44:04.288993Z",
     "shell.execute_reply": "2025-04-04T19:44:04.288077Z"
    },
    "papermill": {
     "duration": 1664.429779,
     "end_time": "2025-04-04T19:44:04.290409",
     "exception": false,
     "start_time": "2025-04-04T19:16:19.860630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19189 accuracy=98.68%\n",
      "Accuracy: 98.68% (18935/19189 correctly classified)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Paths\n",
    "model_path = \"/kaggle/working/fine_tuned_chart_classification_model_v3_5.h5\"\n",
    "image_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/vertical_bar/images\"\n",
    "json_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/vertical_bar/annotations\"\n",
    "\n",
    "chart_types = {\n",
    "    0: \"horizontal_bar\",\n",
    "    1: \"vertical_bar\",\n",
    "    2: \"dot\",\n",
    "    3: \"line\",\n",
    "    4: \"scatter\"\n",
    "}\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Initialize variables\n",
    "correct_predictions = 0\n",
    "total_images = 0\n",
    "\n",
    "# Helper function to preprocess the image\n",
    "def preprocess_image(image_path, target_size=(224, 224)):  # Adjust target size based on your model\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image = img_to_array(image) / 255.0\n",
    "    return np.expand_dims(image, axis=0)\n",
    "\n",
    "# Iterate through images and JSON\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith('.jpg'):\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        json_path = os.path.join(json_folder, filename.replace('.jpg', '.json'))\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    chart_type = data.get(\"chart-type\")  # Adjust key if it's different\n",
    "    \n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "    \n",
    "    # Preprocess image\n",
    "    image = preprocess_image(img_path)\n",
    "    \n",
    "    # Predict chart type\n",
    "    predictions = model.predict(image,verbose = 0)\n",
    "    predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")  # Map number to string\n",
    "    \n",
    "    \n",
    "    # Compare prediction with ground truth\n",
    "    if predicted_chart_type == chart_type:\n",
    "        correct_predictions += 1\n",
    "    total_images += 1\n",
    "    accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "    sys.stdout.write(f\"\\r{total_images} accuracy={accuracy * 100:.2f}%\")\n",
    "    sys.stdout.flush()  # Flush to ensure the line is updated immediately\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_images} correctly classified)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb97f831",
   "metadata": {
    "papermill": {
     "duration": 7.572502,
     "end_time": "2025-04-04T19:44:19.376653",
     "exception": false,
     "start_time": "2025-04-04T19:44:11.804151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**dot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cde32b6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T19:44:34.301525Z",
     "iopub.status.busy": "2025-04-04T19:44:34.301190Z",
     "iopub.status.idle": "2025-04-04T19:51:38.032274Z",
     "shell.execute_reply": "2025-04-04T19:51:38.031167Z"
    },
    "papermill": {
     "duration": 431.227854,
     "end_time": "2025-04-04T19:51:38.033852",
     "exception": false,
     "start_time": "2025-04-04T19:44:26.805998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5131 accuracy=100.00%\n",
      "Accuracy: 100.00% (5131/5131 correctly classified)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Paths\n",
    "model_path = \"/kaggle/working/fine_tuned_chart_classification_model_v3_5.h5\"\n",
    "image_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/dot/images\"\n",
    "json_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/dot/annotations\"\n",
    "\n",
    "chart_types = {\n",
    "    0: \"horizontal_bar\",\n",
    "    1: \"vertical_bar\",\n",
    "    2: \"dot\",\n",
    "    3: \"line\",\n",
    "    4: \"scatter\"\n",
    "}\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Initialize variables\n",
    "correct_predictions = 0\n",
    "total_images = 0\n",
    "\n",
    "# Helper function to preprocess the image\n",
    "def preprocess_image(image_path, target_size=(224, 224)):  # Adjust target size based on your model\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image = img_to_array(image) / 255.0\n",
    "    return np.expand_dims(image, axis=0)\n",
    "\n",
    "# Iterate through images and JSON\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith('.jpg'):\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        json_path = os.path.join(json_folder, filename.replace('.jpg', '.json'))\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    chart_type = data.get(\"chart-type\")  # Adjust key if it's different\n",
    "    \n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "    \n",
    "    # Preprocess image\n",
    "    image = preprocess_image(img_path)\n",
    "    \n",
    "    # Predict chart type\n",
    "    predictions = model.predict(image,verbose = 0)\n",
    "    predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")  # Map number to string\n",
    "    \n",
    "    \n",
    "    # Compare prediction with ground truth\n",
    "    if predicted_chart_type == chart_type:\n",
    "        correct_predictions += 1\n",
    "    total_images += 1\n",
    "    accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "    sys.stdout.write(f\"\\r{total_images} accuracy={accuracy * 100:.2f}%\")\n",
    "    sys.stdout.flush()  # Flush to ensure the line is updated immediately\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_images} correctly classified)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0a68b0",
   "metadata": {
    "papermill": {
     "duration": 7.91924,
     "end_time": "2025-04-04T19:51:53.594311",
     "exception": false,
     "start_time": "2025-04-04T19:51:45.675071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "716af6c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T19:52:09.092316Z",
     "iopub.status.busy": "2025-04-04T19:52:09.092009Z",
     "iopub.status.idle": "2025-04-04T20:28:01.089739Z",
     "shell.execute_reply": "2025-04-04T20:28:01.088845Z"
    },
    "papermill": {
     "duration": 2168.434003,
     "end_time": "2025-04-04T20:28:09.723119",
     "exception": false,
     "start_time": "2025-04-04T19:52:01.289116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24942 accuracy=96.20%\n",
      "Accuracy: 96.20% (23993/24942 correctly classified)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Paths\n",
    "model_path = \"/kaggle/working/fine_tuned_chart_classification_model_v3_5.h5\"\n",
    "image_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/line/images\"\n",
    "json_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/line/annotations\"\n",
    "\n",
    "chart_types = {\n",
    "    0: \"horizontal_bar\",\n",
    "    1: \"vertical_bar\",\n",
    "    2: \"dot\",\n",
    "    3: \"line\",\n",
    "    4: \"scatter\"\n",
    "}\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Initialize variables\n",
    "correct_predictions = 0\n",
    "total_images = 0\n",
    "\n",
    "# Helper function to preprocess the image\n",
    "def preprocess_image(image_path, target_size=(224, 224)):  # Adjust target size based on your model\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image = img_to_array(image) / 255.0\n",
    "    return np.expand_dims(image, axis=0)\n",
    "\n",
    "# Iterate through images and JSON\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith('.jpg'):\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        json_path = os.path.join(json_folder, filename.replace('.jpg', '.json'))\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    chart_type = data.get(\"chart-type\")  # Adjust key if it's different\n",
    "    \n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "    \n",
    "    # Preprocess image\n",
    "    image = preprocess_image(img_path)\n",
    "    \n",
    "    # Predict chart type\n",
    "    predictions = model.predict(image,verbose = 0)\n",
    "    predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")  # Map number to string\n",
    "    \n",
    "    \n",
    "    # Compare prediction with ground truth\n",
    "    if predicted_chart_type == chart_type:\n",
    "        correct_predictions += 1\n",
    "    total_images += 1\n",
    "    accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "    sys.stdout.write(f\"\\r{total_images} accuracy={accuracy * 100:.2f}%\")\n",
    "    sys.stdout.flush()  # Flush to ensure the line is updated immediately\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_images} correctly classified)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f955f4e7",
   "metadata": {
    "papermill": {
     "duration": 8.873648,
     "end_time": "2025-04-04T20:28:27.449657",
     "exception": false,
     "start_time": "2025-04-04T20:28:18.576009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**scatter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eff97a70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T20:28:45.292181Z",
     "iopub.status.busy": "2025-04-04T20:28:45.291853Z",
     "iopub.status.idle": "2025-04-04T20:45:01.868858Z",
     "shell.execute_reply": "2025-04-04T20:45:01.867746Z"
    },
    "papermill": {
     "duration": 985.388682,
     "end_time": "2025-04-04T20:45:01.870556",
     "exception": false,
     "start_time": "2025-04-04T20:28:36.481874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11243 accuracy=95.62%\n",
      "Accuracy: 95.62% (10751/11243 correctly classified)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Paths\n",
    "model_path = \"/kaggle/working/fine_tuned_chart_classification_model_v3_5.h5\"\n",
    "image_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/scatter/images\"\n",
    "json_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/scatter/annotations\"\n",
    "\n",
    "\n",
    "chart_types = {\n",
    "    0: \"horizontal_bar\",\n",
    "    1: \"vertical_bar\",\n",
    "    2: \"dot\",\n",
    "    3: \"line\",\n",
    "    4: \"scatter\"\n",
    "}\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Initialize variables\n",
    "correct_predictions = 0\n",
    "total_images = 0\n",
    "\n",
    "# Helper function to preprocess the image\n",
    "def preprocess_image(image_path, target_size=(224, 224)):  # Adjust target size based on your model\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image = img_to_array(image) / 255.0\n",
    "    return np.expand_dims(image, axis=0)\n",
    "\n",
    "# Iterate through images and JSON\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith('.jpg'):\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        json_path = os.path.join(json_folder, filename.replace('.jpg', '.json'))\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    chart_type = data.get(\"chart-type\")  # Adjust key if it's different\n",
    "    \n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "    \n",
    "    # Preprocess image\n",
    "    image = preprocess_image(img_path)\n",
    "    \n",
    "    # Predict chart type\n",
    "    predictions = model.predict(image,verbose = 0)\n",
    "    predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")  # Map number to string\n",
    "    \n",
    "    \n",
    "    # Compare prediction with ground truth\n",
    "    if predicted_chart_type == chart_type:\n",
    "        correct_predictions += 1\n",
    "    total_images += 1\n",
    "    accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "    sys.stdout.write(f\"\\r{total_images} accuracy={accuracy * 100:.2f}%\")\n",
    "    sys.stdout.flush()  # Flush to ensure the line is updated immediately\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_images} correctly classified)\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 5585780,
     "sourceId": 43873,
     "sourceType": "competition"
    },
    {
     "datasetId": 3259992,
     "sourceId": 5857376,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6209817,
     "sourceId": 10075894,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19643.352814,
   "end_time": "2025-04-04T20:45:19.101734",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-04T15:17:55.748920",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
