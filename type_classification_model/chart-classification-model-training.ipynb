{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":43873,"databundleVersionId":5585780,"sourceType":"competition"},{"sourceId":5857376,"sourceType":"datasetVersion","datasetId":3259992},{"sourceId":10075894,"sourceType":"datasetVersion","datasetId":6209817}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **upload and save resnet50 model**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n\n#save resnet model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nx = GlobalAveragePooling2D()(base_model.output)\nx = Dropout(0.5)(x)  # Add a dropout layer with 50% dropout rate\noutput = Dense(5, activation='softmax')(x)\nmodel = Model(inputs=base_model.input, outputs=output)\nmodel.save('resnet50.h5')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **train the first model for predict type of the chart**","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.models import load_model\n\n# More Horizontal Data Paths\nhrz_images_dir = '/kaggle/input/sortrd-chart-data/selected_images_archive'\nhrz_annotations_dir = '/kaggle/input/sortrd-chart-data/json_files/json_files'\n\ndot_images_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/dot/images'\ndot_annotations_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/dot/annotations'\n\nline_images_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/line/images'\nline_annotations_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/line/annotations'\n\nscatter_images_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/scatter/images'\nscatter_annotations_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/scatter/annotations'\n\nvrt_images_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/vertical_bar/images'\nvrt_annotations_dir = '/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/vertical_bar/annotations'\n\nfiles_paths = [\n    [hrz_images_dir,hrz_annotations_dir],\n    [dot_images_dir,dot_annotations_dir],\n    [line_images_dir,line_annotations_dir],\n    [scatter_images_dir,scatter_annotations_dir],\n    [vrt_images_dir,vrt_annotations_dir]\n]\n\n# Load and preprocess data\ndef load_data(files_paths):\n    image_paths, labels = [], []\n    chart_types = {\n        \"horizontal_bar\": 0,\n        \"vertical_bar\": 1,\n        \"dot\": 2,\n        \"line\": 3,\n        \"scatter\": 4\n    }\n    max_iterations = 2000\n    for charttype in files_paths:\n        iteration_count = 0\n        for filename in os.listdir(charttype[0]):\n            if iteration_count >= max_iterations:\n                break\n            if filename.endswith('.jpg'):\n                img_path = os.path.join(charttype[0], filename)\n                json_path = os.path.join(charttype[1], filename.replace('.jpg', '.json'))\n                \n                with open(json_path, 'r') as f:\n                    data = json.load(f)\n                    chart_type = data.get('chart-type', None)\n                    \n                    # Handle missing or unknown chart types\n                    if chart_type not in chart_types:\n                        print(f\"Unknown chart type '{chart_type}' in {json_path}\")\n                        continue\n                    \n                    label = chart_types[chart_type]\n                    image_paths.append(img_path)\n                    labels.append(label)\n            iteration_count += 1\n    return image_paths, labels\n    \n# Preprocess images\ndef preprocess_image(img_path, label, img_size=(224, 224)):\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, img_size)\n    img = img / 255.0\n    return img, label\n\n# Load dataset\nimage_paths, labels = load_data(files_paths)\n\n# Split into train, validation, and test sets\ntrain_paths, val_paths, train_labels, val_labels = train_test_split(image_paths, labels, test_size=0.3, random_state=42)\n\n# Use a smaller subset of the training dataset for faster training\ntrain_paths = train_paths[:5000]  # Use only 5000 images for training\ntrain_labels = train_labels[:5000]  # Match train labels with train paths\nval_paths = val_paths[:1000]      # Use only 1000 images for validation\nval_labels = val_labels[:1000]    # Match validation labels with validation paths\n\n# Compute class weights to handle imbalance\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(train_labels),\n    y=train_labels\n)\nclass_weights = dict(enumerate(class_weights))\n\n# Create TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\ntrain_dataset = train_dataset.map(lambda x, y: preprocess_image(x, y)).batch(32).shuffle(1000).repeat()\n\nval_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\nval_dataset = val_dataset.map(lambda x, y: preprocess_image(x, y)).batch(32).repeat()\n\n# Define the model\nmodel = load_model('/kaggle/working/resnet50.h5')\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Freeze base model layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Train the model with limited steps per epoch\nmodel.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    steps_per_epoch=100,  # Use only 100 batches per epoch\n    validation_steps=30,  # Use only 30 batches for validation\n    epochs=5\n)\n\n# Unfreeze top layers for fine-tuning\nfor layer in base_model.layers[:-10]:  # Freeze all layers except the last 10\n    layer.trainable = False\nfor layer in base_model.layers[-10:]:\n    layer.trainable = True\n\n# Compile the model for fine-tuning\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-6), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Fine-tune the model\nmodel.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    steps_per_epoch=100,\n    validation_steps=30,\n    epochs=10\n)\n\n# Save the model\nmodel.save('chart_classification_model.h5')\n\n# Evaluate on the validation set\nval_loss, val_accuracy = model.evaluate(val_dataset, steps=30)\nprint(f\"Validation Accuracy: {val_accuracy:.2f}, Validation Loss: {val_loss:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Load original train data**","metadata":{}},{"cell_type":"code","source":"#paths\nimages_dir = '/kaggle/input/benetech-making-graphs-accessible/train/images'\nannotations_dir = '/kaggle/input/benetech-making-graphs-accessible/train/annotations'\n\n# Load and preprocess data\ndef load_data(images_dir,annotations_dir):\n    image_paths, labels = [], []\n    chart_types = {\n        \"horizontal_bar\": 0,\n        \"vertical_bar\": 1,\n        \"dot\": 2,\n        \"line\": 3,\n        \"scatter\": 4\n    }\n    for filename in os.listdir(images_dir):\n        if iteration_count >= max_iterations:\n            break\n        if filename.endswith('.jpg'):\n            img_path = os.path.join(images_dir, filename)\n            json_path = os.path.join(annotations_dir, filename.replace('.jpg', '.json'))\n                \n            with open(json_path, 'r') as f:\n                data = json.load(f)\n                chart_type = data.get('chart-type', None)\n                    \n                # Handle missing or unknown chart types\n                if chart_type not in chart_types:\n                    print(f\"Unknown chart type '{chart_type}' in {json_path}\")\n                    continue\n                    \n                label = chart_types[chart_type]\n                image_paths.append(img_path)\n                labels.append(label)\n    return image_paths, labels","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **check the model on all of the data**","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport json\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Paths\nmodel_path = \"/kaggle/working/chart_classification_model.h5\"\nimage_folder = \"/kaggle/input/benetech-making-graphs-accessible/train/images\"\njson_folder = \"/kaggle/input/benetech-making-graphs-accessible/train/annotations\"\n\nchart_types = {\n    0: \"horizontal_bar\",\n    1: \"vertical_bar\",\n    2: \"dot\",\n    3: \"line\",\n    4: \"scatter\"\n}\n\n# Load the trained model\nmodel = load_model(model_path)\n\n# Initialize variables\ncorrect_predictions = 0\ntotal_images = 0\n\n# Helper function to preprocess the image\ndef preprocess_image(image_path, target_size=(224, 224)):  # Adjust target size based on your model\n    image = load_img(image_path, target_size=target_size)\n    image = img_to_array(image) / 255.0\n    return np.expand_dims(image, axis=0)\n\n# Iterate through images and JSON\nfor filename in os.listdir(image_folder):\n    if filename.endswith('.jpg'):\n        img_path = os.path.join(image_folder, filename)\n        json_path = os.path.join(json_folder, filename.replace('.jpg', '.json'))\n    \n    with open(json_path, 'r') as f:\n        data = json.load(f)\n    \n    chart_type = data.get(\"chart-type\")  # Adjust key if it's different\n    \n    if not os.path.exists(img_path):\n        continue\n    \n    # Preprocess image\n    image = preprocess_image(img_path)\n    \n    # Predict chart type\n    predictions = model.predict(image,verbose = 0)\n    predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n    predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")  # Map number to string\n    \n    \n    # Compare prediction with ground truth\n    if predicted_chart_type == chart_type:\n        correct_predictions += 1\n    total_images += 1\n    accuracy = correct_predictions / total_images if total_images > 0 else 0\n    sys.stdout.write(f\"\\r{total_images} accuracy={accuracy * 100:.2f}%\")\n    sys.stdout.flush()  # Flush to ensure the line is updated immediately\n\n# Calculate accuracy\naccuracy = correct_predictions / total_images if total_images > 0 else 0\nprint(f\"\\nAccuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_images} correctly classified)\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Finetuning the model**","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\n# Paths to the sorted data folders\ndata_paths = {\n    \"horizontal_bar\": \"/kaggle/input/benetech-extra-generated-data/graphs_h\",\n    \"vertical_bar\": \"/kaggle/input/benetech-extra-generated-data/graphs_v\",\n    \"dot\": \"/kaggle/input/benetech-extra-generated-data/graphs_d\",\n    \"line\": \"/kaggle/input/benetech-extra-generated-data/graphs_l\",\n    \"scatter\": \"/kaggle/input/benetech-extra-generated-data/graphs_s\"\n}\n\n# Labels for each folder\nchart_types = {\n    \"horizontal_bar\": 0,\n    \"vertical_bar\": 1,\n    \"dot\": 2,\n    \"line\": 3,\n    \"scatter\": 4\n}\nmax_chart = {\n    \"horizontal_bar\":3000,\n    \"vertical_bar\": 1400,\n    \"dot\": 1400,\n    \"line\": 3000,\n    \"scatter\": 1400\n}\n\n# Function to load and label images\ndef load_images(data_paths, chart_types, max_images_per_class=2000):\n    image_paths, labels = [], []\n    for chart_type, path in data_paths.items():\n        files = os.listdir(path)\n        random.shuffle(files)\n        for i, filename in enumerate(files):\n            if i >= max_chart[chart_type]:  # Limit to max_images_per_class per folder\n                break\n            if filename.endswith('.jpg') or filename.endswith('.png'):  # Support common image formats\n                image_paths.append(os.path.join(path, filename))\n                labels.append(chart_types[chart_type])\n    image_paths, labels = shuffle(image_paths, labels, random_state=0)\n    return image_paths, labels\n\n# Load and label the images\nimage_paths, labels = load_images(data_paths, chart_types)\n\n# Shuffle the data\ndata = list(zip(image_paths, labels))\nnp.random.shuffle(data)\nimage_paths, labels = zip(*data)\n\n# Preprocess images\ndef preprocess_image(img_path, label, img_size=(224, 224)):\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, img_size)\n    img = img / 255.0\n    return img, label\n\n# Split into training and validation sets\ntrain_paths, val_paths, train_labels, val_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n\n# Create TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\ntrain_dataset = train_dataset.map(lambda x, y: preprocess_image(x, y)).batch(32).shuffle(1000).repeat()\n\nval_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\nval_dataset = val_dataset.map(lambda x, y: preprocess_image(x, y)).batch(32).repeat()\n\n# Load the pre-trained model\nmodel = load_model('/kaggle/working/chart_classification_model.h5')\n\n# Freeze base model layers\nfor layer in model.layers[:-10]:  # Freeze all layers except the last 10\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model with limited steps per epoch\nmodel.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    steps_per_epoch=1000,\n    validation_steps=300,\n    epochs=5\n)\nmodel.save('fine_tuned_chart_classification_model_mid_v3_5.h5')\n\n# Unfreeze all layers for fine-tuning\nfor layer in model.layers:\n    layer.trainable = True\n\n# Compile the model with a smaller learning rate for fine-tuning\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-6), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Fine-tune the model\nmodel.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    steps_per_epoch=1000,\n    validation_steps=300,\n    epochs=10\n)\n\n# Save the fine-tuned model\nmodel.save('fine_tuned_chart_classification_model_v3_5.h5')\n\n# Evaluate on the validation set\nval_loss, val_accuracy = model.evaluate(val_dataset, steps=30)\nprint(f\"Validation Accuracy: {val_accuracy:.2f}, Validation Loss: {val_loss:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **check the new model on all data**","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport json\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Paths\nmodel_path = \"fine_tuned_chart_classification_model_v3_5.h5\"\nimage_folder = \"/kaggle/input/benetech-making-graphs-accessible/train/images\"\njson_folder = \"/kaggle/input/benetech-making-graphs-accessible/train/annotations\"\n\nchart_types = {\n    0: \"horizontal_bar\",\n    1: \"vertical_bar\",\n    2: \"dot\",\n    3: \"line\",\n    4: \"scatter\"\n}\n\n# Load the trained model\nmodel = load_model(model_path)\n\n# Initialize variables\ncorrect_predictions = 0\ntotal_images = 0\n\n# Helper function to preprocess the image\ndef preprocess_image(image_path, target_size=(224, 224)):  # Adjust target size based on your model\n    image = load_img(image_path, target_size=target_size)\n    image = img_to_array(image) / 255.0\n    return np.expand_dims(image, axis=0)\n\n# Iterate through images and JSON\nfor filename in os.listdir(image_folder):\n    if filename.endswith('.jpg'):\n        img_path = os.path.join(image_folder, filename)\n        json_path = os.path.join(json_folder, filename.replace('.jpg', '.json'))\n    \n    with open(json_path, 'r') as f:\n        data = json.load(f)\n    \n    chart_type = data.get(\"chart-type\")  # Adjust key if it's different\n    \n    if not os.path.exists(img_path):\n        continue\n    \n    # Preprocess image\n    image = preprocess_image(img_path)\n    \n    # Predict chart type\n    predictions = model.predict(image,verbose = 0)\n    predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n    predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")  # Map number to string\n    \n    \n    # Compare prediction with ground truth\n    if predicted_chart_type == chart_type:\n        correct_predictions += 1\n    total_images += 1\n    accuracy = correct_predictions / total_images if total_images > 0 else 0\n    sys.stdout.write(f\"\\r{total_images} accuracy={accuracy * 100:.2f}%\")\n    sys.stdout.flush()  # Flush to ensure the line is updated immediately\n\n# Calculate accuracy\naccuracy = correct_predictions / total_images if total_images > 0 else 0\nprint(f\"\\nAccuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_images} correctly classified)\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **check new model on each type of graph**","metadata":{}},{"cell_type":"markdown","source":"**Horizontal bar**","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport json\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Paths\nmodel_path = \"/kaggle/working/fine_tuned_chart_classification_model_v3_5.h5\"\nimage_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/horizontal_bar/images\"\njson_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/horizontal_bar/annotations\"\n\nchart_types = {\n    0: \"horizontal_bar\",\n    1: \"vertical_bar\",\n    2: \"dot\",\n    3: \"line\",\n    4: \"scatter\"\n}\n\n# Load the trained model\nmodel = load_model(model_path)\n\n# Initialize variables\ncorrect_predictions = 0\ntotal_images = 0\n\n# Helper function to preprocess the image\ndef preprocess_image(image_path, target_size=(224, 224)):  # Adjust target size based on your model\n    image = load_img(image_path, target_size=target_size)\n    image = img_to_array(image) / 255.0\n    return np.expand_dims(image, axis=0)\n\n# Iterate through images and JSON\nfor filename in os.listdir(image_folder):\n    if filename.endswith('.jpg'):\n        img_path = os.path.join(image_folder, filename)\n        json_path = os.path.join(json_folder, filename.replace('.jpg', '.json'))\n    \n    with open(json_path, 'r') as f:\n        data = json.load(f)\n    \n    chart_type = data.get(\"chart-type\")  # Adjust key if it's different\n    \n    if not os.path.exists(img_path):\n        continue\n    \n    # Preprocess image\n    image = preprocess_image(img_path)\n    \n    # Predict chart type\n    predictions = model.predict(image,verbose = 0)\n    predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n    predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")  # Map number to string\n    \n    \n    # Compare prediction with ground truth\n    if predicted_chart_type == chart_type:\n        correct_predictions += 1\n    total_images += 1\n    accuracy = correct_predictions / total_images if total_images > 0 else 0\n    sys.stdout.write(f\"\\r{total_images} accuracy={accuracy * 100:.2f}%\")\n    sys.stdout.flush()  # Flush to ensure the line is updated immediately\n\n# Calculate accuracy\naccuracy = correct_predictions / total_images if total_images > 0 else 0\nprint(f\"\\nAccuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_images} correctly classified)\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**vertical bar**","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport json\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Paths\nmodel_path = \"/kaggle/working/fine_tuned_chart_classification_model_v3_5.h5\"\nimage_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/vertical_bar/images\"\njson_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/vertical_bar/annotations\"\n\nchart_types = {\n    0: \"horizontal_bar\",\n    1: \"vertical_bar\",\n    2: \"dot\",\n    3: \"line\",\n    4: \"scatter\"\n}\n\n# Load the trained model\nmodel = load_model(model_path)\n\n# Initialize variables\ncorrect_predictions = 0\ntotal_images = 0\n\n# Helper function to preprocess the image\ndef preprocess_image(image_path, target_size=(224, 224)):  # Adjust target size based on your model\n    image = load_img(image_path, target_size=target_size)\n    image = img_to_array(image) / 255.0\n    return np.expand_dims(image, axis=0)\n\n# Iterate through images and JSON\nfor filename in os.listdir(image_folder):\n    if filename.endswith('.jpg'):\n        img_path = os.path.join(image_folder, filename)\n        json_path = os.path.join(json_folder, filename.replace('.jpg', '.json'))\n    \n    with open(json_path, 'r') as f:\n        data = json.load(f)\n    \n    chart_type = data.get(\"chart-type\")  # Adjust key if it's different\n    \n    if not os.path.exists(img_path):\n        continue\n    \n    # Preprocess image\n    image = preprocess_image(img_path)\n    \n    # Predict chart type\n    predictions = model.predict(image,verbose = 0)\n    predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n    predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")  # Map number to string\n    \n    \n    # Compare prediction with ground truth\n    if predicted_chart_type == chart_type:\n        correct_predictions += 1\n    total_images += 1\n    accuracy = correct_predictions / total_images if total_images > 0 else 0\n    sys.stdout.write(f\"\\r{total_images} accuracy={accuracy * 100:.2f}%\")\n    sys.stdout.flush()  # Flush to ensure the line is updated immediately\n\n# Calculate accuracy\naccuracy = correct_predictions / total_images if total_images > 0 else 0\nprint(f\"\\nAccuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_images} correctly classified)\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**dot**","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport json\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Paths\nmodel_path = \"/kaggle/working/fine_tuned_chart_classification_model_v3_5.h5\"\nimage_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/dot/images\"\njson_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/dot/annotations\"\n\nchart_types = {\n    0: \"horizontal_bar\",\n    1: \"vertical_bar\",\n    2: \"dot\",\n    3: \"line\",\n    4: \"scatter\"\n}\n\n# Load the trained model\nmodel = load_model(model_path)\n\n# Initialize variables\ncorrect_predictions = 0\ntotal_images = 0\n\n# Helper function to preprocess the image\ndef preprocess_image(image_path, target_size=(224, 224)):  # Adjust target size based on your model\n    image = load_img(image_path, target_size=target_size)\n    image = img_to_array(image) / 255.0\n    return np.expand_dims(image, axis=0)\n\n# Iterate through images and JSON\nfor filename in os.listdir(image_folder):\n    if filename.endswith('.jpg'):\n        img_path = os.path.join(image_folder, filename)\n        json_path = os.path.join(json_folder, filename.replace('.jpg', '.json'))\n    \n    with open(json_path, 'r') as f:\n        data = json.load(f)\n    \n    chart_type = data.get(\"chart-type\")  # Adjust key if it's different\n    \n    if not os.path.exists(img_path):\n        continue\n    \n    # Preprocess image\n    image = preprocess_image(img_path)\n    \n    # Predict chart type\n    predictions = model.predict(image,verbose = 0)\n    predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n    predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")  # Map number to string\n    \n    \n    # Compare prediction with ground truth\n    if predicted_chart_type == chart_type:\n        correct_predictions += 1\n    total_images += 1\n    accuracy = correct_predictions / total_images if total_images > 0 else 0\n    sys.stdout.write(f\"\\r{total_images} accuracy={accuracy * 100:.2f}%\")\n    sys.stdout.flush()  # Flush to ensure the line is updated immediately\n\n# Calculate accuracy\naccuracy = correct_predictions / total_images if total_images > 0 else 0\nprint(f\"\\nAccuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_images} correctly classified)\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**line**","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport json\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Paths\nmodel_path = \"/kaggle/working/fine_tuned_chart_classification_model_v3_5.h5\"\nimage_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/line/images\"\njson_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/line/annotations\"\n\nchart_types = {\n    0: \"horizontal_bar\",\n    1: \"vertical_bar\",\n    2: \"dot\",\n    3: \"line\",\n    4: \"scatter\"\n}\n\n# Load the trained model\nmodel = load_model(model_path)\n\n# Initialize variables\ncorrect_predictions = 0\ntotal_images = 0\n\n# Helper function to preprocess the image\ndef preprocess_image(image_path, target_size=(224, 224)):  # Adjust target size based on your model\n    image = load_img(image_path, target_size=target_size)\n    image = img_to_array(image) / 255.0\n    return np.expand_dims(image, axis=0)\n\n# Iterate through images and JSON\nfor filename in os.listdir(image_folder):\n    if filename.endswith('.jpg'):\n        img_path = os.path.join(image_folder, filename)\n        json_path = os.path.join(json_folder, filename.replace('.jpg', '.json'))\n    \n    with open(json_path, 'r') as f:\n        data = json.load(f)\n    \n    chart_type = data.get(\"chart-type\")  # Adjust key if it's different\n    \n    if not os.path.exists(img_path):\n        continue\n    \n    # Preprocess image\n    image = preprocess_image(img_path)\n    \n    # Predict chart type\n    predictions = model.predict(image,verbose = 0)\n    predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n    predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")  # Map number to string\n    \n    \n    # Compare prediction with ground truth\n    if predicted_chart_type == chart_type:\n        correct_predictions += 1\n    total_images += 1\n    accuracy = correct_predictions / total_images if total_images > 0 else 0\n    sys.stdout.write(f\"\\r{total_images} accuracy={accuracy * 100:.2f}%\")\n    sys.stdout.flush()  # Flush to ensure the line is updated immediately\n\n# Calculate accuracy\naccuracy = correct_predictions / total_images if total_images > 0 else 0\nprint(f\"\\nAccuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_images} correctly classified)\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**scatter**","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport json\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Paths\nmodel_path = \"/kaggle/working/fine_tuned_chart_classification_model_v3_5.h5\"\nimage_folder = \"/kaggle/input/sortrd-chart-data/sorted_data/sorted_data/scatter/images\"\n.ions\"\n\nchart_types = {\n    0: \"horizontal_bar\",\n    1: \"vertical_bar\",\n    2: \"dot\",\n    3: \"line\",\n    4: \"scatter\"\n}\n\n# Load the trained model\nmodel = load_model(model_path)\n\n# Initialize variables\ncorrect_predictions = 0\ntotal_images = 0\n\n# Helper function to preprocess the image\ndef preprocess_image(image_path, target_size=(224, 224)):  # Adjust target size based on your model\n    image = load_img(image_path, target_size=target_size)\n    image = img_to_array(image) / 255.0\n    return np.expand_dims(image, axis=0)\n\n# Iterate through images and JSON\nfor filename in os.listdir(image_folder):\n    if filename.endswith('.jpg'):\n        img_path = os.path.join(image_folder, filename)\n        json_path = os.path.join(json_folder, filename.replace('.jpg', '.json'))\n    \n    with open(json_path, 'r') as f:\n        data = json.load(f)\n    \n    chart_type = data.get(\"chart-type\")  # Adjust key if it's different\n    \n    if not os.path.exists(img_path):\n        continue\n    \n    # Preprocess image\n    image = preprocess_image(img_path)\n    \n    # Predict chart type\n    predictions = model.predict(image,verbose = 0)\n    predicted_chart_type_index = np.argmax(predictions, axis=1)[0]\n    predicted_chart_type = chart_types.get(predicted_chart_type_index, \"unknown\")  # Map number to string\n    \n    \n    # Compare prediction with ground truth\n    if predicted_chart_type == chart_type:\n        correct_predictions += 1\n    total_images += 1\n    accuracy = correct_predictions / total_images if total_images > 0 else 0\n    sys.stdout.write(f\"\\r{total_images} accuracy={accuracy * 100:.2f}%\")\n    sys.stdout.flush()  # Flush to ensure the line is updated immediately\n\n# Calculate accuracy\naccuracy = correct_predictions / total_images if total_images > 0 else 0\nprint(f\"\\nAccuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_images} correctly classified)\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}